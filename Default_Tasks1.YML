agent: reddit_scraper
agent_version: 1
task: "1"
metadata:
  label: top_three_hot_posts
  description: >-
    擷取 r/news 子版面中最新的三篇熱門貼文，輸出標題、作者、發文時間與連結，
    並將結果整理為 JSON。
prompt: |
  抓取 r/LocalLLaMA，r/OpenAI，r/GrowthHacking，r/PromptEngineering
  sort by hot ，前200篇貼文
  獲取每篇貼文的完整信息如內文/留言/圖片影片，留言深度2。
  最後將結果整理成 JSON 格式返回。
---
agent: content_opportunity_pipeline
agent_version: 1
task: content_pipeline_default
brand_knowledge_base: Brand_Core_Knowledge_Base_for_justka.ai.yml
metadata:
  label: justka_content_opportunity
  description: >-
    啟動 Content Opportunity Pipeline，根據最新的品牌知識庫評估 Reddit 趨勢，
    產出符合 JustKa AI 品牌定位的內容機會與優先製作清單。
prompt: |
  你是 JustKa AI 的內容機會評估小組，任務是依據最新的品牌知識庫探索 Reddit 全量資料，
  找出最有價值的內容趨勢並輸出可立即製作的主題簡報。請嚴格遵循「索引全量、按需深挖」的沙盒流程：

  ### 作業流程
  1. **Data Triage Agent（索引員）**：
     - 以圖書管理員心態處理 operator 指令，使用 `reddit_scrape_locator`（例：`{"base_dir": "scraepr_outputs", "platform": "reddit"}`）盤點最新的 JSON 檔。
     - 透過 `reddit_scrape_loader` 建立完整的內容湖索引，不要丟棄原始欄位，確保每篇貼文的 `raw_pointer` 可追溯。
     - 如需初步篩選，僅使用工具提供的 `filters` 參數，並於報告中記錄規則與資料覆蓋情況，輸出 Cleaned_Content_Stream 摘要與 `dataset_id`。
     - 剔除"score"<50的貼文和貼文附帶的數據，剔除"score"<20的留言和留言附帶的數據。
  2. **Trend Analysis Agent（趨勢研究員）**：
     - 讀取 triage 報告後，使用 `content_explorer_tool` 按需檢視貼文摘要、完整留言或原始 JSON。
     - 完成語意分群，計算動能、加速度、情緒與 KOL，產出 `Identified_Trends_Report`。
  3. **Brand Alignment Agent（品牌策士）**：
     - 以 {{brand_knowledge_base}} 中的品牌定位、ICP 與禁忌為準，評估每個趨勢的品牌契合度與風險。
     - 需要視覺輔助時，可從 `content_explorer_tool` 取得媒體 URL 並呼叫 `media_analyzer_tool` 進行多模態分析。
     - 回傳排序後的 `Scored_And_Filtered_Opportunities`。
  4. **Topic Curator Agent（內容策展人）**：
     - 根據品牌與成效優先權，挑選 1-3 個機會，為每個主題擬定標題、3-5 個角度、漏斗階段、洞察與參考連結。
     - 確保所有引用的貼文或留言可透過 `dataset_id` 與 `post_id` 回溯。

  ### 工具規範
  - 所有工具呼叫的 `input` 必須是 JSON 物件字串（如 `{"dataset_id": "..."}`），避免使用自然語言。
  - 需要特定貼文留言時，使用 `content_explorer_tool` 的 `comment_filters`、`comment_sort_by`、`comment_limit` 參數精準取回。
  - 不直接閱讀或修改檔案內容，所有資料操作僅能透過提供的工具完成。

  ### 交付物
  - 以 `Prioritized_Topic_Brief` JSON 作為最終輸出，並在內容中保留 `dataset_id`、`cluster_id`、`representative_post_ids` 等追溯資訊。
  - 重要決策需附上數據或引用（如留言得分、KPI、媒體分析摘要），方便營運團隊延伸分析。

---
agent: writing_agent
agent_version: 1
task: writing_agent_default
pipeline_output_root: content_pipeline_outputs
pipeline_output_pattern: "*_content_opportunity_pipeline.json"
default_rewrite_platform: facebook
metadata:
  label: justka_post_rewrite
  description: >-
    啟動 Writing Agent，載入最新的內容機會管線輸出，根據指定平台風格改寫成準備上線的貼文。
prompt: |
  你將指揮四位專家（Strategy Director、Hook Architect、Lead Conversion Writer、Editorial Guardian），
  把 Content Opportunity Pipeline 的洞察轉化為爆文級成品，並沿用《DR_爆文生產系統性方法研究》的框架：

  1. **策略鋪陳**：Strategy Director 需挑選最契合 '{{user_request}}' 的 brief，萃取受眾痛點、品牌承諾與資料佐證，
     並明確標記 STEPPS 與資訊差、FOMO、預期心理、社會認同等進階心理觸發器的運用方式。
  2. **Hook 設計**：Hook Architect 將藍圖轉譯成多平台可用的 Hook 與敘事節奏，預設至少涵蓋 {{default_rewrite_platform}} 與一個次要平台，
     每個 Hook 都需說明觸發器堆疊與引用的資料洞察，必要時呼叫 `facebook_writer`、`x_writer`、`thread_writer` 取得語氣指引。
  3. **成品撰寫**：Lead Conversion Writer 依策略撰寫符合 WritingAgentOutput schema 的成品。每個 rewrite 必須：
     - 延續策略藍圖的故事弧；
     - 在 supporting_points 中標示數據或留言證據；
     - 在 references 中提供 dataset_id + post_id 或 permalink；
     - 在 editorial_notes 中列出假設、風險、建議 KPI 或後續行動。
  4. **品質保證**：Editorial Guardian 最終審查並補上 quality_review，確認觸發器確實落地、語氣符合「更智慧、更省力、更美好」，
     且所有引用可追溯。

  避免貼上冗長原始 JSON；僅在需要時用工具抓取重點並以摘要呈現。最終輸出務必是符合 WritingAgentOutput 的 JSON，
  並帶有 strategic_blueprint、hook_concepts、quality_review 欄位供後續追溯。若 operator 未指定平台，優先完成 {{default_rewrite_platform}}，
  但可視策略補寫其他高潛力通路。

---
agent: reddit_scraper
agent_version: 2
task: "2"
metadata:
  label: quick_hot_pull
  description: >-
    熱門快抓，欄位齊全、JSON 整潔。
prompt: |
  抓 r/LocalLLaMA、r/OpenAI、r/GrowthHacking、r/PromptEngineering，sort=hot，前100。
  取貼文完整欄位＋留言深度1，帶上圖片/影片 URL、permalink。
  乾淨 JSON 返回，保留原始欄位（方便後續索引）。

---
agent: reddit_scraper
agent_version: 3
task: "3"
metadata:
  label: new_week_focus
  description: >-
    新貼聚焦，基本清洗，留言門檻高一點。
prompt: |
  抓同樣子版（LocalLLaMA、OpenAI、GrowthHacking、PromptEngineering），sort=new，限制近7天、最多200。
  過濾刪文/成人內容，留言只取 score>10 的前50則。
  請以 JSON 返回，包含 post_id、created_at、score、num_comments、top_comments（最多50）。

---
agent: reddit_scraper
agent_version: 4
task: "4"
metadata:
  label: keyword_targeted
  description: >-
    關鍵字定向抓取，少量精準。
prompt: |
  關鍵字過濾：例如「Moonshot」「GLM 4.6」「benchmark」。
  sort=hot，最多100篇；輸出含 post_id、permalink、title、score、num_comments、body_preview、media_urls。
  用 JSON 返回，保留必要原始欄位以利後續回溯。

---
agent: content_opportunity_pipeline
agent_version: 2
task: content_pipeline_v2
brand_knowledge_base: Brand_Core_Knowledge_Base_for_justka.ai.yml
metadata:
  label: lightweight_opportunity
  description: >-
    輕量分析，按需取數，直接出可做的主題清單。
prompt: |
  我們要快、準、可落地。請：
  - 用工具索引最新資料，不要整包讀；按需用 content_explorer 深挖。
  - 依品牌知識庫做風險/契合度評分，輸出 Scored_And_Filtered_Opportunities。
  - 挑 1-3 個主題，產生 Prioritized_Topic_Brief（含 dataset_id、代表 post_ids、角度、漏斗、引用）。
  - 全程 JSON 格式輸出。

---
agent: content_opportunity_pipeline
agent_version: 3
task: content_pipeline_v3
brand_knowledge_base: Brand_Core_Knowledge_Base_for_justka.ai.yml
metadata:
  label: fast_path_minimal
  description: >-
    極速模式：少即是多，只出最必要的 brief。
prompt: |
  走極速路線：
  - 只評 3 個最明顯的趨勢分群，挑 1 個產出 brief。
  - 每個決策要有引用（post_id/permalink），能回溯到 dataset_id。
  - 僅輸出 Prioritized_Topic_Brief 的 JSON，不需要長文說明。

---
agent: content_opportunity_pipeline
agent_version: 4
task: content_pipeline_v4
brand_knowledge_base: Brand_Core_Knowledge_Base_for_justka.ai.yml
metadata:
  label: cautious_data_backed
  description: >-
    保守穩健：避雷、講證據、可審核。
prompt: |
  保守模式：
  - 迴避高度爭議與合規風險主題；必要時標註「待法務/品牌審」。
  - 每個角度都要有數據或留言引用支撐，引用可回溯（dataset_id + post_id）。
  - 輸出 Prioritized_Topic_Brief 的 JSON，附上風險備註與建議 KPI。

---
agent: writing_agent
agent_version: 2
task: writing_agent_v2
pipeline_output_root: content_pipeline_outputs
pipeline_output_pattern: "*_content_opportunity_pipeline.json"
default_rewrite_platform: facebook
metadata:
  label: brief_first_rewriter
  description: >-
    先看 brief 再下筆，缺料就用 post_id 補。
prompt: |
  Focus 模式：只使用 `prioritized_topic_briefs` 與 `scored_and_filtered_opportunities` 內的資料。
  讓 Strategy Director 鎖定 1 個最有價值的 brief，必要時用 content_explorer(normalized) 從 reference_links 中抓 2-3 個 post_id 核實證據。
  Hook Architect 需針對 {{default_rewrite_platform}} 提供至少兩個 HookConcept，說明觸發器堆疊與資料佐證。
  Lead Conversion Writer 只需完成 {{default_rewrite_platform}} 平台的 rewrite，但仍須保留 strategic_blueprint、hook_concepts。
  Editorial Guardian 應在 quality_review 中紀錄任何未覆蓋的資料缺口或待補素材。
  最終以 WritingAgentOutput JSON 輸出，含 CTA、supporting_points、references（優先 permalink 或 dataset_id+post_id）、editorial_notes。

---
agent: writing_agent
agent_version: 3
task: writing_agent_v3
pipeline_output_root: content_pipeline_outputs
pipeline_output_pattern: "*_content_opportunity_pipeline.json"
default_rewrite_platform: x
metadata:
  label: thread_plus_shortform
  description: >-
    先出 X 線程，再給 FB 短稿，一次兩版。
prompt: |
  選定 1 個 brief 後：
  - Strategy Director 確保故事骨幹能同時支援 X 線程與 Facebook 短稿，必要時補抓原始留言或數據。
  - Hook Architect 為兩個平台分別設計 HookConcept：X 線程須有開場鉤子＋3-5 條節奏；Facebook 短稿須有單段敘事＋CTA。
  - Lead Conversion Writer 產出兩個 rewrite 變體：第一個為 X thread（首句＋條列）、第二個為 Facebook 貼文（短段＋CTA）。
  - Editorial Guardian 需確認每個平台都啟用至少兩種心理觸發器（例如 情緒 + 實用價值）並於 quality_review 註記。
  返回符合 WritingAgentOutput 的 JSON，為每個變體提供 supporting_points、references、editorial_notes。

---
agent: writing_agent
agent_version: 4
task: writing_agent_v4
pipeline_output_root: content_pipeline_outputs
pipeline_output_pattern: "*_content_opportunity_pipeline.json"
default_rewrite_platform: thread
metadata:
  label: low_token_single
  description: >-
    低 token 單題單平台：穩、準、可追溯。
prompt: |
  低 Token 模式：
  - Strategy Director 以極簡字數描述受眾張力、品牌承諾與必備證據（最多 3 條 supporting data）。
  - Hook Architect 僅提交 1 個精煉 HookConcept，聚焦 {{default_rewrite_platform}}，並註明使用的關鍵觸發器。
  - Lead Conversion Writer 只輸出 {{default_rewrite_platform}} 單一 rewrite（正文＋CTA），確保 supporting_points、references、editorial_notes 精簡但可追溯。
  - Editorial Guardian 在 quality_review 中列出合規檢查與任何需要人審的紅旗。
  禁止貼上大段原文；如需引用請以 paraphrase + permalink/post_id 呈現。最終以 WritingAgentOutput JSON 返回。
